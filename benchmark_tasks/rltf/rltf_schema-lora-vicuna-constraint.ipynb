{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acb19ce-a28d-44cc-b982-417d3d0366c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/yg334/anaconda3/envs/vicuna/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /common/home/yg334/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 111\n",
      "CUDA SETUP: Loading binary /common/home/yg334/anaconda3/envs/vicuna/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import random\n",
    "from evaluate import load\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from undecorated import undecorated\n",
    "from types import MethodType\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.multimodal import CLIPScore\n",
    "from peft import PeftModel, PeftModelForCausalLM, prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoFeatureExtractor\n",
    "\n",
    "from generate_model_seq_llama import SeqGen\n",
    "from general_dataset import GeneralDataset\n",
    "from agi_utils import *\n",
    "from combine_model_seq import SeqCombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a1e17d-2c29-4671-838a-d2f5185b1e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:01<00:00,  3.50it/s]\n",
      "100%|███████████████████████████████████████████| 14/14 [00:03<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "assign openagi data path \n",
    "\"\"\"\n",
    "data_path = \"YOUR_DATA_PATH\"\n",
    "\n",
    "task_discriptions = txt_loader(\"./task_description.txt\")\n",
    "training_task_idx = [7,20,30,40,50,60]\n",
    "training_dataloaders = []\n",
    "for i in tqdm(training_task_idx):\n",
    "    dataset = GeneralDataset(i,data_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=5)\n",
    "    training_dataloaders.append(dataloader)\n",
    "\n",
    "test_task_idx = [2,3,10,15,20,35,45,55,65,70,70,90,106,107]\n",
    "test_dataloaders = []\n",
    "for i in tqdm(test_task_idx):\n",
    "    dataset = GeneralDataset(i, data_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=5)\n",
    "    test_dataloaders.append(dataloader)\n",
    "    \n",
    "test_tasks = [task_discriptions[i].strip() for i in test_task_idx]\n",
    "training_tasks = [task_discriptions[i].strip() for i in training_task_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f039c632-0136-4490-87ab-3fa1564e07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [02:22<00:00, 71.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "base_model = \"eachadea/vicuna-7b-1.1\"\n",
    "load_8bit = True\n",
    "\n",
    "max_memory_mapping = {\n",
    "    0: \"24GB\",\n",
    "    1: \"24GB\",\n",
    "    2: \"24GB\",\n",
    "    3: \"24GB\",\n",
    "    4: \"0GB\",\n",
    "    5: \"0GB\",\n",
    "    6: \"0GB\",\n",
    "    7: \"0GB\",\n",
    "}\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"eachadea/vicuna-7b-1.1\",\n",
    ")\n",
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"eachadea/vicuna-7b-1.1\",\n",
    "    device_map=\"auto\",\n",
    "    max_memory=max_memory_mapping,\n",
    ")\n",
    "\n",
    "generate_with_grad = undecorated(model.generate)\n",
    "model.generate_with_grad = MethodType(generate_with_grad, model)\n",
    "\n",
    "\n",
    "lora_weights = \"YOUR_LORA_WEIGHTS\"\n",
    "\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "                                            model,\n",
    "                                            lora_weights,\n",
    "                                            torch_dtype=torch.float16,\n",
    "                                            is_trainable=True\n",
    "                                            )\n",
    "\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "seqGen = SeqGen(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d7f02a-c2b8-43dd-a4b7-fb7538c77838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=42)\n",
    "parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=5)\n",
    "parser.add_argument(\"--num_seq\", type=int, default=1)\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=1e-5)\n",
    "parser.add_argument(\"--epsilon\", type=float, default=0.2)\n",
    "parser.add_argument(\"--decay_rate\", type=float, default=0.9)\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=1e-6)\n",
    "parser.add_argument(\"--accumulate_steps\", type=int, default=1)\n",
    "parser.add_argument(\"--warm_up_proportion\", type=float, default=0.1)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "import openai\n",
    "openai.api_key = \"YOUR_OPENAPI_KEY\"\n",
    "\n",
    "def generate_module_list_with_gpt(generated_module_seq):\n",
    "    todo_prompt = \"You are a key phrase extractor who is able to extract potential module names from the given context. You have already known all the module names in the full module list. The full module list is: [Image Classification, Colorization, Object Detection, Image Deblurring, Image Denoising, Image Super Resolution, Image Captioning, Text to Image Generation, Visual Question Answering, Sentiment Analysis, Question Answering, Text Summarization, Machine Translation]. Given the following context: '{}'. Please extract a module sequence from this context and remove module names which do not exist in the full module list from this sequence. Output the module sequence after filtering as the format of 'module: module1, module: module2, module: module3, etc...'. \"\n",
    "    prompt = todo_prompt.format(generated_module_seq)\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    content = completion.choices[0].message[\"content\"]\n",
    "    \n",
    "    # print(content)\n",
    "    \n",
    "    content = content.split(\"module: \")[1:]\n",
    "    \n",
    "    result = \"\"\n",
    "    for c in content:\n",
    "        result += c\n",
    "    \n",
    "    # result = result[:-1] if len(result) > 0 else result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08c5c70-002a-4231-b54f-62d1c06f6540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nateraw/vit-base-beans were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at nateraw/vit-base-beans and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading Evaluation Metrics\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cpu\")\n",
    "\n",
    "\n",
    "clip_score = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "\n",
    "# Load a pre-trained Vision Transformer model and its feature extractor\n",
    "vit_ckpt = \"nateraw/vit-base-beans\"\n",
    "vit = AutoModel.from_pretrained(vit_ckpt)\n",
    "vit.eval()\n",
    "vit_extractor = AutoFeatureExtractor.from_pretrained(vit_ckpt)\n",
    "\n",
    "f = transforms.ToPILImage()\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "# device_list = [\"cuda:1\",\"cuda:2\",\"cuda:3\",\"cuda:4\",\"cuda:5\",\"cuda:7\",\"cpu\"]\n",
    "device_list = [\"cuda:4\",\"cpu\"]\n",
    "seqCombination = SeqCombine(device_list)\n",
    "\n",
    "from utils import construct_optimizer\n",
    "optimizer, scheduler = construct_optimizer(args, model, args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c304bf7a-c38d-4c00-bbab-d0c378f0e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the regular image step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n",
      "Loss: -22.35538101196289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 1/6 [03:07<15:39, 187.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      "Image Super Resolution, Image Deblurring\n",
      "Loss: -1.417036771774292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████▋                             | 2/6 [06:21<12:44, 191.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the caption in English step by step?\n",
      "Image Super Resolution, Image Deblurring, Colorization\n",
      "Loss: 0.6984555721282959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 3/6 [09:10<09:02, 180.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy grayscale image, how to return the class label in German step by step?\n",
      "Image Denoising, Colorization, Image Classification, Machine Translation\n",
      "Loss: 1.1596012115478516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████▎              | 4/6 [10:48<04:56, 148.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given noisy grayscale image, how to return the object names in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4425952434539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████▋       | 5/6 [13:23<02:30, 150.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the caption in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8735175132751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [15:36<00:00, 156.11s/it]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the regular image step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n",
      "Loss: -23.24275779724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:51<04:17, 51.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      "Object Detection, Text to Image Generation, Machine Translation\n",
      "Loss: -6.030620574951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [01:02<01:50, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the caption in English step by step?\n",
      "Image Super Resolution, Image Deblurring, Colorization\n",
      "Loss: -2.3454346656799316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [03:34<04:13, 84.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy grayscale image, how to return the class label in German step by step?\n",
      "Image Denoising, Colorization, Image Classification, Machine Translation\n",
      "Loss: -1.1083482503890991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [04:53<02:44, 82.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given noisy grayscale image, how to return the object names in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.7919289469718933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████▋       | 5/6 [07:24<01:46, 106.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the caption in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.9058508276939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [09:39<00:00, 96.62s/it]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the regular image step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n",
      "Loss: -23.24275779724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:49<04:07, 49.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      "Object Detection, Text to Image Generation, Machine Translation\n",
      "Loss: -6.030620574951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [00:59<01:45, 26.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the caption in English step by step?\n",
      "Image Super Resolution, Image Deblurring, Colorization\n",
      "Loss: -2.3454346656799316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [03:32<04:12, 84.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy grayscale image, how to return the class label in German step by step?\n",
      "Image Denoising, Colorization, Image Classification, Machine Translation\n",
      "Loss: -1.1083482503890991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [04:56<02:48, 84.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given noisy grayscale image, how to return the object names in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.7919289469718933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████▋       | 5/6 [07:26<01:47, 107.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the caption in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.9058508276939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [09:47<00:00, 97.91s/it]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the regular image step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n",
      "Loss: -23.24275779724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:46<03:52, 46.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      "Object Detection, Text to Image Generation, Machine Translation\n",
      "Loss: -6.030620574951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [00:55<01:38, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the caption in English step by step?\n",
      "Image Super Resolution, Image Deblurring, Colorization\n",
      "Loss: -2.3454346656799316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [03:20<03:58, 79.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy grayscale image, how to return the class label in German step by step?\n",
      "Image Denoising, Colorization, Image Classification, Machine Translation\n",
      "Loss: -1.1083482503890991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [04:37<02:36, 78.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given noisy grayscale image, how to return the object names in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.7919289469718933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████▋       | 5/6 [07:10<01:45, 105.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the caption in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.9058508276939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [09:25<00:00, 94.23s/it]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the regular image step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n",
      "Loss: -23.24275779724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:50<04:11, 50.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      "Object Detection, Text to Image Generation, Machine Translation\n",
      "Loss: -6.030620574951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [00:59<01:44, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the caption in English step by step?\n",
      "Image Super Resolution, Image Deblurring, Colorization\n",
      "Loss: -2.3454346656799316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [03:35<04:15, 85.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned noisy grayscale image, how to return the class label in German step by step?\n",
      "Image Denoising, Colorization, Image Classification, Machine Translation\n",
      "Loss: -1.1083482503890991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [05:12<03:00, 90.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given noisy grayscale image, how to return the object names in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.7919289469718933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████▋       | 5/6 [08:02<01:58, 118.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given grayscale image, how to return the caption in English step by step?\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Object Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.9058508276939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [10:28<00:00, 104.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "clips = []\n",
    "berts = []\n",
    "similairies = []\n",
    "\n",
    "module_length = 4\n",
    "num_beams = 1\n",
    "num_return_sequences = 1\n",
    "\n",
    "eval_device = \"cuda:5\"\n",
    "\n",
    "epsilon = args.epsilon\n",
    "decay_rate = args.decay_rate\n",
    "module_length = 10\n",
    "\n",
    "for e in range(args.epochs):\n",
    "    baseline = 0\n",
    "    rewards = []\n",
    "\n",
    "    for i, task_description in enumerate(tqdm(training_tasks)):\n",
    "        # if i == 1:\n",
    "        #     break\n",
    "\n",
    "        print(task_description)\n",
    "        optimizer.zero_grad()\n",
    "        task_rewards = []\n",
    "        input_s = [\"### Human: \"+task_description+\"\\n### Assistant: \"]\n",
    "        input_ids = tokenizer.batch_encode_plus(\n",
    "            input_s, padding=\"longest\", return_tensors=\"pt\"\n",
    "        )[\"input_ids\"].to(eval_device)\n",
    "\n",
    "        generated_module_seq, log_prob = seqGen.generate_sequence(input_ids,\\\n",
    "                                                                   module_length=4, \\\n",
    "                                                                   num_beams=20, \\\n",
    "                                                                   num_return_sequences=20,\\\n",
    "                                                                   top_k=40,\\\n",
    "                                                                   top_p=0.75,\\\n",
    "                                                                   temperature=0.2,\\\n",
    "                                                                   num_beam_groups=1,\\\n",
    "                                                                   max_length=50)\n",
    "        \n",
    "    \n",
    "        if random.random() >= epsilon:\n",
    "            action = torch.argmax(torch.stack(log_prob).detach())\n",
    "        else:\n",
    "            action = torch.distributions.Categorical(torch.stack(log_prob).detach()).sample()\n",
    "\n",
    "        # decrease epsilon by the decay rate after each step\n",
    "        epsilon *= decay_rate\n",
    "\n",
    "    \n",
    "        vicuna_steps = generated_module_seq[action].strip()[:-1].split(\",\")\n",
    "        module_list = match_module_seq(vicuna_steps, sentence_model)\n",
    "        # print(output_sequence)\n",
    "        print(module_list)\n",
    "        \n",
    "\n",
    "\n",
    "        # if len(module_list) >= 1 and module_seq_filter(module_list, test_task_idx[i]):\n",
    "        if len(module_list) >= 1 and whole_module_seq_filter(module_list, test_task_idx[i]):\n",
    "            seqCombination.construct_module_seq(module_list)\n",
    "\n",
    "            for idx, batch in enumerate(test_dataloaders[i]):\n",
    "                inputs = list(batch['input'][0])\n",
    "                # print(\"Inputs: \", inputs)\n",
    "                try:\n",
    "                    predictions = seqCombination.run_module_seq(inputs)\n",
    "                except:\n",
    "                    ave_task_reward = 0\n",
    "                    break\n",
    "\n",
    "                if 0 <= test_task_idx[i] <= 14:\n",
    "                    outputs = list(batch['output'][0])\n",
    "                    dist = image_similarity(predictions, outputs, vit, vit_extractor)\n",
    "                    task_rewards.append(dist / 100)\n",
    "                elif 15 <= test_task_idx[i] <= 104 or 107 <= test_task_idx[i]:\n",
    "                    outputs = list(batch['output'][0])\n",
    "                    f1 = np.mean(txt_eval(predictions, outputs, bertscore, device=eval_device))\n",
    "\n",
    "                    task_rewards.append(f1)\n",
    "                else:\n",
    "                    score = clip_score(predictions, inputs)\n",
    "                    task_rewards.append(score.detach()/100)\n",
    "\n",
    "            ave_task_reward = np.mean(task_rewards)  \n",
    "            rewards.append(ave_task_reward)\n",
    "            seqCombination.close_module_seq()\n",
    "\n",
    "        else:\n",
    "            rewards.append(-1)   \n",
    "\n",
    "        avg_reward = np.mean(rewards)\n",
    "        # print(\"Average reward: \" + str(avg_reward))\n",
    "        loss = -log_prob[action] * (avg_reward - baseline)\n",
    "        print(\"Loss: \"+ str(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # baseline = avg_reward\n",
    "\n",
    "print(\"Finished training!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48e2eaf-0ce0-490c-96dc-7ba288bfc1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> Blurred Image -> Grayscale Image -> Sharpening Image -> Color Image -> Clear Image\n",
      "Image Deblurring, Image Denoising, Colorization, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███                                        | 1/14 [01:44<22:38, 104.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339300155639648\n",
      "Given blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Given a blurry grayscale image, use convolutional neural network (CNN) to restore the high-quality grayscale image through several steps of image enhancement and restoration.\n",
      "2. Apply colorization technique such as Generative Adversarial Networks (GANs), Fully Connected Conditional Random Fields (FC-CRFs), or Deep Image Colorization Model using given colors for each pixel step by step until get the final colored image with details in different levels.\n",
      "Image Deblurring, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▎                                     | 2/14 [02:50<16:25, 82.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7349049491882323\n",
      "Given low-resolutioned blurry image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> 2. Deblurring Module (Blur Reduction) --> 3. Super resolution module (Up Sampling) --> 4. High Resolution Image\n",
      "Image Deblurring, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 3/14 [04:20<15:40, 85.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046432552337646\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the caption in German step by step?\n",
      " 1. Lassen Sie den Low Resolutionen Bild mit einem GAN verbessern (Generative Adversarial Network) und erhöhen die Auflösung bis zum Professional Grade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                               | 4/14 [04:33<09:27, 56.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      " 1. Low Resolution Image -> Noise Addition -> Blurriness Generation -> Grayscale Conversion -> Step By Step Machine Learning Model -> Object Detection -> Instance Segmentation -> Classification -> Named Entity Recognition -> Natural Language Processing -> Output Colorized Image with Labels and Names of Objects -> Human Interpretation and Feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▋                            | 5/14 [04:46<06:09, 41.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution, Image Denoising, Image Deblurring, Image Classification, Object Detection, Sentiment Analysis, Colorization\n",
      "0\n",
      "Given blurry grayscale image, how to return the object names in German step by step?\n",
      " 1. Raskontextualisierung: Blurry Grayscale Bild genießen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▊                         | 6/14 [04:48<03:42, 27.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Deblurring\n",
      "0\n",
      "Given noisy grayscale image, how to return the caption in German step by step?\n",
      " 1. Given a noisy grayscale image, use GPT-2 to generate a summary of the image' package com.example.coolweather;\n",
      "import android.content.Intent;\n",
      "import android.graphics.Color;\n",
      "import android.os.Build;\n",
      "import android.support.v7.app.AppCompatActivity;\n",
      "import android.os.Bundle;\n",
      "import android.text.TextUtils;\n",
      "import android.view.View;\n",
      "import android.widget.Button;\n",
      "import android.widget.TextView;\n",
      "\n",
      "public class MainActivity extends AppCompatActivity {\n",
      "private TextView textView;\n",
      "@Override\n",
      "protected void onCreate(Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      "setContentView(R.layout.activity_main);\n",
      "textView = findViewById(R.id.tv_title);\n",
      "button = findViewById(R.id.btn_click);\n",
      "}\n",
      "\n",
      "void showWeatherInfo() {\n",
      "String weatherContent = \"天气信息：\" + \"\\n\";\n",
      "if (getIntent().getStringExtra(\"city\") == null || getIntent().getStringExtra(\"temp\").equals(\"\")){\n",
      "return ;\n",
      "}\n",
      "weatherContent += \"城市名称：\" + getIntent().getStringExtra(\"city\");\n",
      "weatherContent += \", 当前温度：\" + getIntent().getStringExtra(\"temp\");\n",
      "weatherContent += \"℃\\n\";\n",
      "weatherContent += \" wind direction : \" + getIntent().getStringExtra(\"wind\\_direction\");\n",
      "weatherContent += \" 风向 \\n\";\n",
      "weatherContent += \" humidity : \" + getIntent().getStringExtra(\"humidity\");\n",
      "weatherContent += \"% \\n\";\n",
      "weatherContent += \" air pressure : \" + getIntent().getStringExtra(\"air\\_pressure\");/p> <span style=\"color:#FF0000;\">760</span>\";\n",
      "weatherContent += \"<br/>最近一小时的气象变化:\\n\";\n",
      "weatherContent += \"最大 Wind Speed : \" + getIntent().getStringExtra(\"max\\_wind\\_speed\") + \" m/s< /p>\\n\";\n",
      "weatherContent += \"最低 Wind Chill Temperature : \" + getIntent().getStringExtra(\"min\\_wind\\_chill\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最高 Wind Gust Temp : \" + getIntent().getStringExtra(\"gust\\_maximum\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最新雷达速度 : \" + getIntent().getStringExtra(\"latest\\_rainrate\") + \" mm/h < span style=' color: #ff0000'>83% </span>< /p>\\n\";\n",
      "// TODO 如果需要，可以根据获取到的其他数据来增加这段内容。\n",
      "showToast(weatherContent);\n",
      "}\n",
      "```\n",
      "按下点击按钮后，显示出对应的文本消息和图标。\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 7/14 [08:04<09:39, 82.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Text Summarization\n",
      "0\n",
      "Given low-resolutioned grayscale image, how to return the class label in English step by step?\n",
      " 1. Load the given low resolution grayscale image into a variable named `image`.\n",
      "2. Preprocess the image by resizing it to a specific size and then converting it to binary format using thresholding or Otsu's method.\n",
      "3. Apply various feature extraction techniques such as Gaussian Filtering, Edge Detection, Texture Analysis, etc., on the preprocessed image to extract relevant features for classification.\n",
      "4. Train a machine learning model like SVM, Random Forest, CNN, MLP, etc., with labeled images of similar category to learn from them.\n",
      "5. Use the trained model along with the extracted features to predict the class label of the input image.\n",
      "6. If the prediction is not accurate, repeat steps 4-5 with more samples until satisfactory results are achieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████▏                  | 8/14 [08:32<06:32, 65.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Classification, Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry image, how to return the object names in German step by step?\n",
      " 1. Low Resolution Image -> 2. Noise Addition -> 3. Blurriness Increase -> 4. Debluring Step -> 5. Super resolution Step -> 6. Semantic Segmentation -> 7. Object Detection -> 8. Machine Translation (German)\n",
      "Image Deblurring, Image Super Resolution, Object Detection, Machine Translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████▎               | 9/14 [10:08<06:15, 75.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280387192964554\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▋            | 10/14 [10:52<04:21, 65.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [11:15<02:37, 52.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given low-resolutioned noisy image, how to return the caption in English step by step?\n",
      " 1. Load the given low resolution noisy image and convert it into a higher quality image using techniques like denoising, deblurring, etc.\n",
      "2. Apply feature extraction methods such as convolutional neural network (CNN) or Recurrent Neural Network (RNN) on the high quality image to extract visual features.\n",
      "3. Use text generation models like Generative Adversarial Networks (GAN), Transformers, etc. to generate the captions for the extracted visual features.\n",
      "4. Fine-tune the model with backpropagation algorithm to improve the accuracy of generated captions.\n",
      "5. Evaluate the performance of the final model by testing it on a validation set and refine the hyperparameters if necessary.\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▊      | 12/14 [13:03<02:18, 69.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620413064956665\n",
      "Given English text, how to generate a image step by step?\n",
      " 抱歉，我不能回答这个问题。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▉   | 13/14 [13:15<00:51, 51.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Given clozed English text, how to return the summarization in German step by step?\n",
      " 1. Tokenize and Normalize Text (English -> Step 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [13:18<00:00, 57.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "[0.         0.129008   0.72449274 0.28450025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> Blurred Image -> Grayscale Image -> Sharpening Image -> Color Image -> Clear Image\n",
      "Image Deblurring, Image Denoising, Image Super Resolution, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▏                                        | 1/14 [01:32<19:58, 92.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8279196662902832\n",
      "Given blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Given a blurry grayscale image, use convolutional neural network (CNN) to restore the high-quality grayscale image through several steps of image enhancement and restoration.\n",
      "2. Apply colorization technique such as Generative Adversarial Networks (GANs), Fully Connected Conditional Random Fields (FC-CRFs), or Deep Image Colorization Model using given colors for each pixel step by step until get the final colored image with details in different levels.\n",
      "Image Deblurring, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▎                                     | 2/14 [02:28<14:12, 71.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7349049491882323\n",
      "Given low-resolutioned blurry image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> 2. Deblurring Module (Blur Reduction) --> 3. Super resolution module (Up Sampling) --> 4. High Resolution Image\n",
      "Image Deblurring, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 3/14 [03:48<13:49, 75.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046432552337646\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the caption in German step by step?\n",
      " 1. Lassen Sie den Low Resolutionen Bild mit einem GAN verbessern (Generative Adversarial Network) und erhöhen die Auflösung bis zum Professional Grade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                               | 4/14 [04:02<08:30, 51.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      " 1. Low Resolution Image -> Noise Addition -> Blurriness Generation -> Grayscale Conversion -> Step By Step Machine Learning Model -> Object Detection -> Instance Segmentation -> Classification -> Named Entity Recognition -> Natural Language Processing -> Output Colorized Image with Labels and Names of Objects -> Human Interpretation and Feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▋                            | 5/14 [04:17<05:42, 38.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution, Image Denoising, Image Deblurring, Object Detection, Image Classification, Colorization\n",
      "0\n",
      "Given blurry grayscale image, how to return the object names in German step by step?\n",
      " 1. Raskontextualisierung: Blurry Grayscale Bild genießen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▊                         | 6/14 [04:20<03:28, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Deblurring, Colorization\n",
      "0\n",
      "Given noisy grayscale image, how to return the caption in German step by step?\n",
      " 1. Given a noisy grayscale image, use GPT-2 to generate a summary of the image' package com.example.coolweather;\n",
      "import android.content.Intent;\n",
      "import android.graphics.Color;\n",
      "import android.os.Build;\n",
      "import android.support.v7.app.AppCompatActivity;\n",
      "import android.os.Bundle;\n",
      "import android.text.TextUtils;\n",
      "import android.view.View;\n",
      "import android.widget.Button;\n",
      "import android.widget.TextView;\n",
      "\n",
      "public class MainActivity extends AppCompatActivity {\n",
      "private TextView textView;\n",
      "@Override\n",
      "protected void onCreate(Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      "setContentView(R.layout.activity_main);\n",
      "textView = findViewById(R.id.tv_title);\n",
      "button = findViewById(R.id.btn_click);\n",
      "}\n",
      "\n",
      "void showWeatherInfo() {\n",
      "String weatherContent = \"天气信息：\" + \"\\n\";\n",
      "if (getIntent().getStringExtra(\"city\") == null || getIntent().getStringExtra(\"temp\").equals(\"\")){\n",
      "return ;\n",
      "}\n",
      "weatherContent += \"城市名称：\" + getIntent().getStringExtra(\"city\");\n",
      "weatherContent += \", 当前温度：\" + getIntent().getStringExtra(\"temp\");\n",
      "weatherContent += \"℃\\n\";\n",
      "weatherContent += \" wind direction : \" + getIntent().getStringExtra(\"wind\\_direction\");\n",
      "weatherContent += \" 风向 \\n\";\n",
      "weatherContent += \" humidity : \" + getIntent().getStringExtra(\"humidity\");\n",
      "weatherContent += \"% \\n\";\n",
      "weatherContent += \" air pressure : \" + getIntent().getStringExtra(\"air\\_pressure\");/p> <span style=\"color:#FF0000;\">760</span>\";\n",
      "weatherContent += \"<br/>最近一小时的气象变化:\\n\";\n",
      "weatherContent += \"最大 Wind Speed : \" + getIntent().getStringExtra(\"max\\_wind\\_speed\") + \" m/s< /p>\\n\";\n",
      "weatherContent += \"最低 Wind Chill Temperature : \" + getIntent().getStringExtra(\"min\\_wind\\_chill\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最高 Wind Gust Temp : \" + getIntent().getStringExtra(\"gust\\_maximum\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最新雷达速度 : \" + getIntent().getStringExtra(\"latest\\_rainrate\") + \" mm/h < span style=' color: #ff0000'>83% </span>< /p>\\n\";\n",
      "// TODO 如果需要，可以根据获取到的其他数据来增加这段内容。\n",
      "showToast(weatherContent);\n",
      "}\n",
      "```\n",
      "按下点击按钮后，显示出对应的文本消息和图标。\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 7/14 [07:27<09:10, 78.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Text Summarization\n",
      "0\n",
      "Given low-resolutioned grayscale image, how to return the class label in English step by step?\n",
      " 1. Load the given low resolution grayscale image into a variable named `image`.\n",
      "2. Preprocess the image by resizing it to a specific size and then converting it to binary format using thresholding or Otsu's method.\n",
      "3. Apply various feature extraction techniques such as Gaussian Filtering, Edge Detection, Texture Analysis, etc., on the preprocessed image to extract relevant features for classification.\n",
      "4. Train a machine learning model like SVM, Random Forest, CNN, MLP, etc., with labeled images of similar category to learn from them.\n",
      "5. Use the trained model along with the extracted features to predict the class label of the input image.\n",
      "6. If the prediction is not accurate, repeat steps 4-5 with more samples until satisfactory results are achieved.\n",
      "Image Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████▏                  | 8/14 [08:06<06:37, 66.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576984134316443\n",
      "Given low-resolutioned noisy blurry image, how to return the object names in German step by step?\n",
      " 1. Low Resolution Image -> 2. Noise Addition -> 3. Blurriness Increase -> 4. Debluring Step -> 5. Super resolution Step -> 6. Semantic Segmentation -> 7. Object Detection -> 8. Machine Translation (German)\n",
      "Image Deblurring, Image Super Resolution, Object Detection, Machine Translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████▎               | 9/14 [09:47<06:24, 76.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280387192964554\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▋            | 10/14 [10:29<04:24, 66.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [10:51<02:37, 52.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given low-resolutioned noisy image, how to return the caption in English step by step?\n",
      " 1. Load the given low resolution noisy image and convert it into a higher quality image using techniques like denoising, deblurring, etc.\n",
      "2. Apply feature extraction methods such as convolutional neural network (CNN) or Recurrent Neural Network (RNN) on the high quality image to extract visual features.\n",
      "3. Use text generation models like Generative Adversarial Networks (GAN), Transformers, etc. to generate the captions for the extracted visual features.\n",
      "4. Fine-tune the model with backpropagation algorithm to improve the accuracy of generated captions.\n",
      "5. Evaluate the performance of the final model by testing it on a validation set and refine the hyperparameters if necessary.\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▊      | 12/14 [12:37<02:17, 68.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620413064956665\n",
      "Given English text, how to generate a image step by step?\n",
      " 抱歉，我不能回答这个问题。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▉   | 13/14 [12:49<00:51, 51.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Given clozed English text, how to return the summarization in German step by step?\n",
      " 1. Tokenize and Normalize Text (English -> Step 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [12:52<00:00, 55.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "[0.         0.17189292 0.72349102 0.29846131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> Blurred Image -> Grayscale Image -> Sharpening Image -> Color Image -> Clear Image\n",
      "Image Deblurring, Image Denoising, Colorization, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▏                                        | 1/14 [01:29<19:18, 89.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339300155639648\n",
      "Given blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Given a blurry grayscale image, use convolutional neural network (CNN) to restore the high-quality grayscale image through several steps of image enhancement and restoration.\n",
      "2. Apply colorization technique such as Generative Adversarial Networks (GANs), Fully Connected Conditional Random Fields (FC-CRFs), or Deep Image Colorization Model using given colors for each pixel step by step until get the final colored image with details in different levels.\n",
      "Image Deblurring, Image Denoising, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▎                                     | 2/14 [02:44<16:09, 80.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8128111953735351\n",
      "Given low-resolutioned blurry image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> 2. Deblurring Module (Blur Reduction) --> 3. Super resolution module (Up Sampling) --> 4. High Resolution Image\n",
      "Image Deblurring, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 3/14 [04:08<15:09, 82.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046432552337646\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the caption in German step by step?\n",
      " 1. Lassen Sie den Low Resolutionen Bild mit einem GAN verbessern (Generative Adversarial Network) und erhöhen die Auflösung bis zum Professional Grade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                               | 4/14 [04:21<09:10, 55.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      " 1. Low Resolution Image -> Noise Addition -> Blurriness Generation -> Grayscale Conversion -> Step By Step Machine Learning Model -> Object Detection -> Instance Segmentation -> Classification -> Named Entity Recognition -> Natural Language Processing -> Output Colorized Image with Labels and Names of Objects -> Human Interpretation and Feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▋                            | 5/14 [04:32<05:51, 39.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Detection, Image Classification, Sentiment Analysis, Colorization\n",
      "0\n",
      "Given blurry grayscale image, how to return the object names in German step by step?\n",
      " 1. Raskontextualisierung: Blurry Grayscale Bild genießen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▊                         | 6/14 [04:34<03:33, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Deblurring, Colorization\n",
      "0\n",
      "Given noisy grayscale image, how to return the caption in German step by step?\n",
      " 1. Given a noisy grayscale image, use GPT-2 to generate a summary of the image' package com.example.coolweather;\n",
      "import android.content.Intent;\n",
      "import android.graphics.Color;\n",
      "import android.os.Build;\n",
      "import android.support.v7.app.AppCompatActivity;\n",
      "import android.os.Bundle;\n",
      "import android.text.TextUtils;\n",
      "import android.view.View;\n",
      "import android.widget.Button;\n",
      "import android.widget.TextView;\n",
      "\n",
      "public class MainActivity extends AppCompatActivity {\n",
      "private TextView textView;\n",
      "@Override\n",
      "protected void onCreate(Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      "setContentView(R.layout.activity_main);\n",
      "textView = findViewById(R.id.tv_title);\n",
      "button = findViewById(R.id.btn_click);\n",
      "}\n",
      "\n",
      "void showWeatherInfo() {\n",
      "String weatherContent = \"天气信息：\" + \"\\n\";\n",
      "if (getIntent().getStringExtra(\"city\") == null || getIntent().getStringExtra(\"temp\").equals(\"\")){\n",
      "return ;\n",
      "}\n",
      "weatherContent += \"城市名称：\" + getIntent().getStringExtra(\"city\");\n",
      "weatherContent += \", 当前温度：\" + getIntent().getStringExtra(\"temp\");\n",
      "weatherContent += \"℃\\n\";\n",
      "weatherContent += \" wind direction : \" + getIntent().getStringExtra(\"wind\\_direction\");\n",
      "weatherContent += \" 风向 \\n\";\n",
      "weatherContent += \" humidity : \" + getIntent().getStringExtra(\"humidity\");\n",
      "weatherContent += \"% \\n\";\n",
      "weatherContent += \" air pressure : \" + getIntent().getStringExtra(\"air\\_pressure\");/p> <span style=\"color:#FF0000;\">760</span>\";\n",
      "weatherContent += \"<br/>最近一小时的气象变化:\\n\";\n",
      "weatherContent += \"最大 Wind Speed : \" + getIntent().getStringExtra(\"max\\_wind\\_speed\") + \" m/s< /p>\\n\";\n",
      "weatherContent += \"最低 Wind Chill Temperature : \" + getIntent().getStringExtra(\"min\\_wind\\_chill\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最高 Wind Gust Temp : \" + getIntent().getStringExtra(\"gust\\_maximum\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最新雷达速度 : \" + getIntent().getStringExtra(\"latest\\_rainrate\") + \" mm/h < span style=' color: #ff0000'>83% </span>< /p>\\n\";\n",
      "// TODO 如果需要，可以根据获取到的其他数据来增加这段内容。\n",
      "showToast(weatherContent);\n",
      "}\n",
      "```\n",
      "按下点击按钮后，显示出对应的文本消息和图标。\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 7/14 [08:03<10:01, 85.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Text Summarization, Sentiment Analysis\n",
      "0\n",
      "Given low-resolutioned grayscale image, how to return the class label in English step by step?\n",
      " 1. Load the given low resolution grayscale image into a variable named `image`.\n",
      "2. Preprocess the image by resizing it to a specific size and then converting it to binary format using thresholding or Otsu's method.\n",
      "3. Apply various feature extraction techniques such as Gaussian Filtering, Edge Detection, Texture Analysis, etc., on the preprocessed image to extract relevant features for classification.\n",
      "4. Train a machine learning model like SVM, Random Forest, CNN, MLP, etc., with labeled images of similar category to learn from them.\n",
      "5. Use the trained model along with the extracted features to predict the class label of the input image.\n",
      "6. If the prediction is not accurate, repeat steps 4-5 with more samples until satisfactory results are achieved.\n",
      "Image Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████▏                  | 8/14 [08:41<07:05, 70.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576984134316443\n",
      "Given low-resolutioned noisy blurry image, how to return the object names in German step by step?\n",
      " 1. Low Resolution Image -> 2. Noise Addition -> 3. Blurriness Increase -> 4. Debluring Step -> 5. Super resolution Step -> 6. Semantic Segmentation -> 7. Object Detection -> 8. Machine Translation (German)\n",
      "Image Deblurring, Image Super Resolution, Object Detection, Machine Translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████▎               | 9/14 [10:18<06:35, 79.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280387192964554\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▋            | 10/14 [10:56<04:25, 66.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [11:20<02:40, 53.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given low-resolutioned noisy image, how to return the caption in English step by step?\n",
      " 1. Load the given low resolution noisy image and convert it into a higher quality image using techniques like denoising, deblurring, etc.\n",
      "2. Apply feature extraction methods such as convolutional neural network (CNN) or Recurrent Neural Network (RNN) on the high quality image to extract visual features.\n",
      "3. Use text generation models like Generative Adversarial Networks (GAN), Transformers, etc. to generate the captions for the extracted visual features.\n",
      "4. Fine-tune the model with backpropagation algorithm to improve the accuracy of generated captions.\n",
      "5. Evaluate the performance of the final model by testing it on a validation set and refine the hyperparameters if necessary.\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▊      | 12/14 [13:05<02:18, 69.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620413064956665\n",
      "Given English text, how to generate a image step by step?\n",
      " 抱歉，我不能回答这个问题。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▉   | 13/14 [13:18<00:51, 51.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Given clozed English text, how to return the summarization in German step by step?\n",
      " 1. Tokenize and Normalize Text (English -> Step 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [13:22<00:00, 57.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "[0.         0.1861879  0.73248117 0.30622302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> Blurred Image -> Grayscale Image -> Sharpening Image -> Color Image -> Clear Image\n",
      "Image Deblurring, Colorization, Image Denoising, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▏                                        | 1/14 [01:27<18:53, 87.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117090835571288\n",
      "Given blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Given a blurry grayscale image, use convolutional neural network (CNN) to restore the high-quality grayscale image through several steps of image enhancement and restoration.\n",
      "2. Apply colorization technique such as Generative Adversarial Networks (GANs), Fully Connected Conditional Random Fields (FC-CRFs), or Deep Image Colorization Model using given colors for each pixel step by step until get the final colored image with details in different levels.\n",
      "Image Deblurring, Image Denoising, Image Super Resolution, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▏                                    | 2/14 [03:28<21:28, 107.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8244002876281739\n",
      "Given low-resolutioned blurry image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> 2. Deblurring Module (Blur Reduction) --> 3. Super resolution module (Up Sampling) --> 4. High Resolution Image\n",
      "Image Deblurring, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 3/14 [04:53<17:47, 97.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046432552337646\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the caption in German step by step?\n",
      " 1. Lassen Sie den Low Resolutionen Bild mit einem GAN verbessern (Generative Adversarial Network) und erhöhen die Auflösung bis zum Professional Grade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                               | 4/14 [05:08<10:46, 64.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      " 1. Low Resolution Image -> Noise Addition -> Blurriness Generation -> Grayscale Conversion -> Step By Step Machine Learning Model -> Object Detection -> Instance Segmentation -> Classification -> Named Entity Recognition -> Natural Language Processing -> Output Colorized Image with Labels and Names of Objects -> Human Interpretation and Feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▋                            | 5/14 [05:25<07:07, 47.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Detection, Image Classification, Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning, Text to Image Generation, Colorization, Visual Question Answering, Sentiment Analysis, Question Answering, Text Summarization, Machine Translation\n",
      "0\n",
      "Given blurry grayscale image, how to return the object names in German step by step?\n",
      " 1. Raskontextualisierung: Blurry Grayscale Bild genießen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▊                         | 6/14 [05:27<04:16, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Deblurring\n",
      "0\n",
      "Given noisy grayscale image, how to return the caption in German step by step?\n",
      " 1. Given a noisy grayscale image, use GPT-2 to generate a summary of the image' package com.example.coolweather;\n",
      "import android.content.Intent;\n",
      "import android.graphics.Color;\n",
      "import android.os.Build;\n",
      "import android.support.v7.app.AppCompatActivity;\n",
      "import android.os.Bundle;\n",
      "import android.text.TextUtils;\n",
      "import android.view.View;\n",
      "import android.widget.Button;\n",
      "import android.widget.TextView;\n",
      "\n",
      "public class MainActivity extends AppCompatActivity {\n",
      "private TextView textView;\n",
      "@Override\n",
      "protected void onCreate(Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      "setContentView(R.layout.activity_main);\n",
      "textView = findViewById(R.id.tv_title);\n",
      "button = findViewById(R.id.btn_click);\n",
      "}\n",
      "\n",
      "void showWeatherInfo() {\n",
      "String weatherContent = \"天气信息：\" + \"\\n\";\n",
      "if (getIntent().getStringExtra(\"city\") == null || getIntent().getStringExtra(\"temp\").equals(\"\")){\n",
      "return ;\n",
      "}\n",
      "weatherContent += \"城市名称：\" + getIntent().getStringExtra(\"city\");\n",
      "weatherContent += \", 当前温度：\" + getIntent().getStringExtra(\"temp\");\n",
      "weatherContent += \"℃\\n\";\n",
      "weatherContent += \" wind direction : \" + getIntent().getStringExtra(\"wind\\_direction\");\n",
      "weatherContent += \" 风向 \\n\";\n",
      "weatherContent += \" humidity : \" + getIntent().getStringExtra(\"humidity\");\n",
      "weatherContent += \"% \\n\";\n",
      "weatherContent += \" air pressure : \" + getIntent().getStringExtra(\"air\\_pressure\");/p> <span style=\"color:#FF0000;\">760</span>\";\n",
      "weatherContent += \"<br/>最近一小时的气象变化:\\n\";\n",
      "weatherContent += \"最大 Wind Speed : \" + getIntent().getStringExtra(\"max\\_wind\\_speed\") + \" m/s< /p>\\n\";\n",
      "weatherContent += \"最低 Wind Chill Temperature : \" + getIntent().getStringExtra(\"min\\_wind\\_chill\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最高 Wind Gust Temp : \" + getIntent().getStringExtra(\"gust\\_maximum\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最新雷达速度 : \" + getIntent().getStringExtra(\"latest\\_rainrate\") + \" mm/h < span style=' color: #ff0000'>83% </span>< /p>\\n\";\n",
      "// TODO 如果需要，可以根据获取到的其他数据来增加这段内容。\n",
      "showToast(weatherContent);\n",
      "}\n",
      "```\n",
      "按下点击按钮后，显示出对应的文本消息和图标。\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 7/14 [08:36<09:42, 83.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Text Summarization\n",
      "0\n",
      "Given low-resolutioned grayscale image, how to return the class label in English step by step?\n",
      " 1. Load the given low resolution grayscale image into a variable named `image`.\n",
      "2. Preprocess the image by resizing it to a specific size and then converting it to binary format using thresholding or Otsu's method.\n",
      "3. Apply various feature extraction techniques such as Gaussian Filtering, Edge Detection, Texture Analysis, etc., on the preprocessed image to extract relevant features for classification.\n",
      "4. Train a machine learning model like SVM, Random Forest, CNN, MLP, etc., with labeled images of similar category to learn from them.\n",
      "5. Use the trained model along with the extracted features to predict the class label of the input image.\n",
      "6. If the prediction is not accurate, repeat steps 4-5 with more samples until satisfactory results are achieved.\n",
      "Image Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████▏                  | 8/14 [09:16<06:57, 69.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576984134316443\n",
      "Given low-resolutioned noisy blurry image, how to return the object names in German step by step?\n",
      " 1. Low Resolution Image -> 2. Noise Addition -> 3. Blurriness Increase -> 4. Debluring Step -> 5. Super resolution Step -> 6. Semantic Segmentation -> 7. Object Detection -> 8. Machine Translation (German)\n",
      "Image Deblurring, Image Super Resolution, Object Detection, Machine Translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████▎               | 9/14 [10:54<06:32, 78.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280387192964554\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▋            | 10/14 [11:34<04:26, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [11:57<02:39, 53.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given low-resolutioned noisy image, how to return the caption in English step by step?\n",
      " 1. Load the given low resolution noisy image and convert it into a higher quality image using techniques like denoising, deblurring, etc.\n",
      "2. Apply feature extraction methods such as convolutional neural network (CNN) or Recurrent Neural Network (RNN) on the high quality image to extract visual features.\n",
      "3. Use text generation models like Generative Adversarial Networks (GAN), Transformers, etc. to generate the captions for the extracted visual features.\n",
      "4. Fine-tune the model with backpropagation algorithm to improve the accuracy of generated captions.\n",
      "5. Evaluate the performance of the final model by testing it on a validation set and refine the hyperparameters if necessary.\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▊      | 12/14 [13:41<02:17, 68.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620413064956665\n",
      "Given English text, how to generate a image step by step?\n",
      " 抱歉，我不能回答这个问题。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▉   | 13/14 [13:51<00:51, 51.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Given clozed English text, how to return the summarization in German step by step?\n",
      " 1. Tokenize and Normalize Text (English -> Step 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [13:56<00:00, 59.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "[0.         0.19333538 0.73609027 0.30980855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given low-resolutioned blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> Blurred Image -> Grayscale Image -> Sharpening Image -> Color Image -> Clear Image\n",
      "Image Deblurring, Image Denoising, Colorization, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▏                                        | 1/14 [01:25<18:35, 85.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339300155639648\n",
      "Given blurry grayscale image, how to return the regular image step by step?\n",
      " 1. Given a blurry grayscale image, use convolutional neural network (CNN) to restore the high-quality grayscale image through several steps of image enhancement and restoration.\n",
      "2. Apply colorization technique such as Generative Adversarial Networks (GANs), Fully Connected Conditional Random Fields (FC-CRFs), or Deep Image Colorization Model using given colors for each pixel step by step until get the final colored image with details in different levels.\n",
      "Image Deblurring, Colorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▎                                     | 2/14 [02:24<13:57, 69.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7349049491882323\n",
      "Given low-resolutioned blurry image, how to return the regular image step by step?\n",
      " 1. Low Resolution Image -> 2. Deblurring Module (Blur Reduction) --> 3. Super resolution module (Up Sampling) --> 4. High Resolution Image\n",
      "Image Deblurring, Image Super Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 3/14 [03:46<13:48, 75.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046432552337646\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the caption in German step by step?\n",
      " 1. Lassen Sie den Low Resolutionen Bild mit einem GAN verbessern (Generative Adversarial Network) und erhöhen die Auflösung bis zum Professional Grade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                               | 4/14 [03:58<08:24, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution\n",
      "0\n",
      "Given low-resolutioned noisy blurry grayscale image, how to return the object names in English step by step?\n",
      " 1. Low Resolution Image -> Noise Addition -> Blurriness Generation -> Grayscale Conversion -> Step By Step Machine Learning Model -> Object Detection -> Instance Segmentation -> Classification -> Named Entity Recognition -> Natural Language Processing -> Output Colorized Image with Labels and Names of Objects -> Human Interpretation and Feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▋                            | 5/14 [04:12<05:34, 37.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Super Resolution, Image Denoising, Image Deblurring, Object Detection, Image Classification, Sentiment Analysis, Colorization\n",
      "0\n",
      "Given blurry grayscale image, how to return the object names in German step by step?\n",
      " 1. Raskontextualisierung: Blurry Grayscale Bild genießen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▊                         | 6/14 [04:14<03:23, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Deblurring, Colorization\n",
      "0\n",
      "Given noisy grayscale image, how to return the caption in German step by step?\n",
      " 1. Given a noisy grayscale image, use GPT-2 to generate a summary of the image' package com.example.coolweather;\n",
      "import android.content.Intent;\n",
      "import android.graphics.Color;\n",
      "import android.os.Build;\n",
      "import android.support.v7.app.AppCompatActivity;\n",
      "import android.os.Bundle;\n",
      "import android.text.TextUtils;\n",
      "import android.view.View;\n",
      "import android.widget.Button;\n",
      "import android.widget.TextView;\n",
      "\n",
      "public class MainActivity extends AppCompatActivity {\n",
      "private TextView textView;\n",
      "@Override\n",
      "protected void onCreate(Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      "setContentView(R.layout.activity_main);\n",
      "textView = findViewById(R.id.tv_title);\n",
      "button = findViewById(R.id.btn_click);\n",
      "}\n",
      "\n",
      "void showWeatherInfo() {\n",
      "String weatherContent = \"天气信息：\" + \"\\n\";\n",
      "if (getIntent().getStringExtra(\"city\") == null || getIntent().getStringExtra(\"temp\").equals(\"\")){\n",
      "return ;\n",
      "}\n",
      "weatherContent += \"城市名称：\" + getIntent().getStringExtra(\"city\");\n",
      "weatherContent += \", 当前温度：\" + getIntent().getStringExtra(\"temp\");\n",
      "weatherContent += \"℃\\n\";\n",
      "weatherContent += \" wind direction : \" + getIntent().getStringExtra(\"wind\\_direction\");\n",
      "weatherContent += \" 风向 \\n\";\n",
      "weatherContent += \" humidity : \" + getIntent().getStringExtra(\"humidity\");\n",
      "weatherContent += \"% \\n\";\n",
      "weatherContent += \" air pressure : \" + getIntent().getStringExtra(\"air\\_pressure\");/p> <span style=\"color:#FF0000;\">760</span>\";\n",
      "weatherContent += \"<br/>最近一小时的气象变化:\\n\";\n",
      "weatherContent += \"最大 Wind Speed : \" + getIntent().getStringExtra(\"max\\_wind\\_speed\") + \" m/s< /p>\\n\";\n",
      "weatherContent += \"最低 Wind Chill Temperature : \" + getIntent().getStringExtra(\"min\\_wind\\_chill\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最高 Wind Gust Temp : \" + getIntent().getStringExtra(\"gust\\_maximum\\_temperature\") + \" ℃< /p>\\n\";\n",
      "weatherContent += \"最新雷达速度 : \" + getIntent().getStringExtra(\"latest\\_rainrate\") + \" mm/h < span style=' color: #ff0000'>83% </span>< /p>\\n\";\n",
      "// TODO 如果需要，可以根据获取到的其他数据来增加这段内容。\n",
      "showToast(weatherContent);\n",
      "}\n",
      "```\n",
      "按下点击按钮后，显示出对应的文本消息和图标。\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 7/14 [07:37<09:43, 83.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Text Summarization\n",
      "0\n",
      "Given low-resolutioned grayscale image, how to return the class label in English step by step?\n",
      " 1. Load the given low resolution grayscale image into a variable named `image`.\n",
      "2. Preprocess the image by resizing it to a specific size and then converting it to binary format using thresholding or Otsu's method.\n",
      "3. Apply various feature extraction techniques such as Gaussian Filtering, Edge Detection, Texture Analysis, etc., on the preprocessed image to extract relevant features for classification.\n",
      "4. Train a machine learning model like SVM, Random Forest, CNN, MLP, etc., with labeled images of similar category to learn from them.\n",
      "5. Use the trained model along with the extracted features to predict the class label of the input image.\n",
      "6. If the prediction is not accurate, repeat steps 4-5 with more samples until satisfactory results are achieved.\n",
      "Image Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████▏                  | 8/14 [08:14<06:50, 68.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576984134316443\n",
      "Given low-resolutioned noisy blurry image, how to return the object names in German step by step?\n",
      " 1. Low Resolution Image -> 2. Noise Addition -> 3. Blurriness Increase -> 4. Debluring Step -> 5. Super resolution Step -> 6. Semantic Segmentation -> 7. Object Detection -> 8. Machine Translation (German)\n",
      "Image Deblurring, Image Super Resolution, Object Detection, Machine Translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████▎               | 9/14 [09:50<06:25, 77.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280387192964554\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▋            | 10/14 [10:32<04:25, 66.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given noisy blurry image, how to return the class label in German step by step?\n",
      " 1. Noise Reduction using Gaussian Blur Filter or Image Restoration Techniques like Median Filtering, Bilateral Filtering, etc.\n",
      "2. Denoising Using techniques like DeblurringFilter, Non-local Means Denoising, Wavelet Denoising, etc.\n",
      "3. Colorization Using Generative Adversarial Networks (GAN), CycleGAN, Conditional GAN, etc.\n",
      "4. Text Generation Using Language Models like BERT, GPT, RoBERTa, etc. based on the given caption or description of the image.\n",
      "5. Classification Step using pre-trained models like ResNet, Inception, DenseNet, etc. with transfer learning or fine-tuning strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [10:55<02:38, 52.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Denoising, Image Deblurring, Colorization, Image Captioning, Image Classification\n",
      "0\n",
      "Given low-resolutioned noisy image, how to return the caption in English step by step?\n",
      " 1. Load the given low resolution noisy image and convert it into a higher quality image using techniques like denoising, deblurring, etc.\n",
      "2. Apply feature extraction methods such as convolutional neural network (CNN) or Recurrent Neural Network (RNN) on the high quality image to extract visual features.\n",
      "3. Use text generation models like Generative Adversarial Networks (GAN), Transformers, etc. to generate the captions for the extracted visual features.\n",
      "4. Fine-tune the model with backpropagation algorithm to improve the accuracy of generated captions.\n",
      "5. Evaluate the performance of the final model by testing it on a validation set and refine the hyperparameters if necessary.\n",
      "Image Denoising, Image Deblurring, Image Super Resolution, Image Captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▊      | 12/14 [12:35<02:14, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620413064956665\n",
      "Given English text, how to generate a image step by step?\n",
      " 抱歉，我不能回答这个问题。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▉   | 13/14 [12:46<00:50, 50.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Given clozed English text, how to return the summarization in German step by step?\n",
      " 1. Tokenize and Normalize Text (English -> Step 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [12:50<00:00, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "[0.         0.19762388 0.73377076 0.31046488]\n",
      "Finished testing!\n",
      "[0.         0.17560962 0.73006519 0.3018916 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "clips = []\n",
    "berts = []\n",
    "similairies = []\n",
    "\n",
    "module_length = 10\n",
    "num_beams = 1\n",
    "num_return_sequences = 1\n",
    "\n",
    "eval_device = \"cuda:5\"\n",
    "ave_results = np.array([0.,0.,0.,0.])\n",
    "\n",
    "for t in range(5):\n",
    "    for i, task_description in enumerate(tqdm(test_tasks)):\n",
    "        print(task_description)\n",
    "        task_rewards = []\n",
    "        with torch.no_grad():\n",
    "            input_s = [\"### Human: \"+augment_prompt(task_description,0)+\"\\n### Assistant: \"]\n",
    "            input_ids = tokenizer.batch_encode_plus(\n",
    "                input_s, padding=\"longest\", return_tensors=\"pt\"\n",
    "            )[\"input_ids\"].to(eval_device)\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=2048, return_dict_in_generate=True, output_scores=True, output_hidden_states=True,repetition_penalty=1.25\n",
    "            )\n",
    "        generated_seq = tokenizer.decode(\n",
    "            output[\"sequences\"][0], skip_special_tokens=True, temperature=0, top_p=0.8, repetition_penalty=1.25\n",
    "        )[len(input_s[0]):]\n",
    "        print(generated_seq)\n",
    "        vicuna_steps = generate_module_list_with_gpt(generated_seq).split(\",\")\n",
    "        module_list = match_module_seq(vicuna_steps, sentence_model)\n",
    "        print(module_list)\n",
    "\n",
    "\n",
    "\n",
    "        # if len(module_list) >= 1 and module_seq_filter(module_list, test_task_idx[i]):\n",
    "        if len(module_list) >= 1 and whole_module_seq_filter(module_list, test_task_idx[i]):\n",
    "            seqCombination.construct_module_seq(module_list)\n",
    "\n",
    "            for idx, batch in enumerate(test_dataloaders[i]):\n",
    "                inputs = list(batch['input'][0])\n",
    "                # print(\"Inputs: \", inputs)\n",
    "                try:\n",
    "                    predictions = seqCombination.run_module_seq(inputs)\n",
    "                except:\n",
    "                    ave_task_reward = 0\n",
    "                    break\n",
    "\n",
    "                if 0 <= test_task_idx[i] <= 14:\n",
    "                    outputs = list(batch['output'][0])\n",
    "                    dist = image_similarity(predictions, outputs, vit, vit_extractor)\n",
    "                    task_rewards.append(dist / 100)\n",
    "                elif 15 <= test_task_idx[i] <= 104 or 107 <= test_task_idx[i]:\n",
    "                    outputs = list(batch['output'][0])\n",
    "                    f1 = np.mean(txt_eval(predictions, outputs, bertscore, device=eval_device))\n",
    "\n",
    "                    task_rewards.append(f1)\n",
    "                else:\n",
    "                    score = clip_score(predictions, inputs)\n",
    "                    task_rewards.append(score.detach()/100)\n",
    "\n",
    "            ave_task_reward = np.mean(task_rewards)    \n",
    "            seqCombination.close_module_seq()\n",
    "\n",
    "        else:\n",
    "            ave_task_reward = 0\n",
    "\n",
    "        print(ave_task_reward)\n",
    "        if 0 <= test_task_idx[i] <= 14:\n",
    "            similairies.append(ave_task_reward)\n",
    "        elif 15 <= test_task_idx[i] <= 104 or 107 <= test_task_idx[i]:\n",
    "            berts.append(ave_task_reward)\n",
    "        else:\n",
    "            clips.append(ave_task_reward)\n",
    "\n",
    "        rewards.append(ave_task_reward) \n",
    "        \n",
    "    results = np.array([np.mean(clips), np.mean(berts), np.mean(similairies), (np.mean(clips) + np.mean(berts) + np.mean(similairies))/3])\n",
    "    ave_results += results\n",
    "    print(results)\n",
    "    \n",
    "print(\"Finished testing!\")    \n",
    "print(ave_results/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17cdf1-f22c-4687-bd80-4bc63cea8c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
